{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret , frame=cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from IPython.display import display,Image\n",
    "from ultralytics.yolo.v8.detect.predict import DetectionPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('D:/weights/runs/detect/train10/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mwhile\u001b[39;00m cp\u001b[39m.\u001b[39misOpened():\n\u001b[0;32m      3\u001b[0m     ret,frame\u001b[39m=\u001b[39mcp\u001b[39m.\u001b[39mread()\n\u001b[1;32m----> 4\u001b[0m     cv2\u001b[39m.\u001b[39;49mimshow(\u001b[39m'\u001b[39;49m\u001b[39mWebcam\u001b[39;49m\u001b[39m'\u001b[39;49m,frame)\n\u001b[0;32m      5\u001b[0m     result\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mpredict(source\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m, show\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, conf\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m1\u001b[39m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "cp=cv2.VideoCapture(0)\n",
    "while cp.isOpened():\n",
    "    ret,frame=cp.read()\n",
    "    cv2.imshow('Webcam',frame)\n",
    "    result=model.predict(source='0', show=True, conf=0.5)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1/1: 0... Success  (inf frames of shape 640x480 at 30.00 FPS)\n",
      "\n",
      "\n",
      "    WARNING  stream/video/webcam/dir predict source will accumulate results in RAM unless `stream=True` is passed,\n",
      "    causing potential out-of-memory errors for large sources or long-running streams/videos.\n",
      "\n",
      "    Usage:\n",
      "        results = model(source=..., stream=True)  # generator of Results objects\n",
      "        for r in results:\n",
      "            boxes = r.boxes  # Boxes object for bbox outputs\n",
      "            masks = r.masks  # Masks object for segment masks outputs\n",
      "            probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "0: 256x320 300 humans, 1124.3ms\n",
      "0: 256x320 300 humans, 23.1ms\n",
      "0: 256x320 300 humans, 16.1ms\n",
      "0: 256x320 300 humans, 14.3ms\n",
      "0: 256x320 300 humans, 16.0ms\n",
      "0: 256x320 300 humans, 47.2ms\n",
      "0: 256x320 300 humans, 53.1ms\n",
      "0: 256x320 300 humans, 42.2ms\n",
      "0: 256x320 300 humans, 31.9ms\n",
      "0: 256x320 300 humans, 30.9ms\n",
      "0: 256x320 300 humans, 48.4ms\n",
      "0: 256x320 300 humans, 48.3ms\n",
      "0: 256x320 300 humans, 46.5ms\n",
      "0: 256x320 300 humans, 49.3ms\n",
      "0: 256x320 300 humans, 51.5ms\n",
      "0: 256x320 300 humans, 49.6ms\n",
      "0: 256x320 300 humans, 54.2ms\n",
      "0: 256x320 300 humans, 52.9ms\n",
      "0: 256x320 300 humans, 57.3ms\n",
      "0: 256x320 300 humans, 55.4ms\n",
      "0: 256x320 300 humans, 89.3ms\n",
      "0: 256x320 300 humans, 77.5ms\n",
      "0: 256x320 300 humans, 64.0ms\n",
      "0: 256x320 300 humans, 25.7ms\n",
      "0: 256x320 300 humans, 27.7ms\n",
      "0: 256x320 300 humans, 28.9ms\n",
      "0: 256x320 300 humans, 23.7ms\n",
      "0: 256x320 300 humans, 25.7ms\n",
      "0: 256x320 300 humans, 23.5ms\n",
      "0: 256x320 300 humans, 24.1ms\n",
      "0: 256x320 300 humans, 23.9ms\n",
      "0: 256x320 300 humans, 24.1ms\n",
      "0: 256x320 300 humans, 23.8ms\n",
      "0: 256x320 300 humans, 24.9ms\n",
      "0: 256x320 300 humans, 23.4ms\n",
      "0: 256x320 300 humans, 24.0ms\n",
      "0: 256x320 300 humans, 24.4ms\n",
      "0: 256x320 300 humans, 29.9ms\n",
      "0: 256x320 300 humans, 24.1ms\n",
      "0: 256x320 300 humans, 44.0ms\n",
      "0: 256x320 300 humans, 44.5ms\n",
      "0: 256x320 300 humans, 45.4ms\n",
      "0: 256x320 300 humans, 76.2ms\n",
      "0: 256x320 300 humans, 76.6ms\n",
      "0: 256x320 300 humans, 77.4ms\n",
      "0: 256x320 300 humans, 77.2ms\n",
      "0: 256x320 300 humans, 76.1ms\n",
      "0: 256x320 300 humans, 76.9ms\n",
      "0: 256x320 300 humans, 75.7ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mpredict(source\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m0\u001b[39;49m\u001b[39m'\u001b[39;49m, save\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, imgsz\u001b[39m=\u001b[39;49m\u001b[39m320\u001b[39;49m, conf\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\raksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\raksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py:246\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor, \u001b[39m'\u001b[39m\u001b[39mset_prompts\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    245\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 246\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mpredict_cli(source\u001b[39m=\u001b[39msource) \u001b[39mif\u001b[39;00m is_cli \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor(source\u001b[39m=\u001b[39;49msource, stream\u001b[39m=\u001b[39;49mstream)\n",
      "File \u001b[1;32mc:\\Users\\raksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:197\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_inference(source, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    196\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream_inference(source, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\raksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:56\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m             \u001b[39m# Pass the last request to the generator and get its response\u001b[39;00m\n\u001b[0;32m     55\u001b[0m             \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 56\u001b[0m                 response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(request)\n\u001b[0;32m     58\u001b[0m \u001b[39m# We let the exceptions raised above by the generator's `.throw` or\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m# `.send` methods bubble up to our caller, except for StopIteration\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m     \u001b[39m# The generator informed us that it is done: take whatever its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[39m# returned value (if any) was and indicate that we're done too\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[39m# by returning it (see docs for python's return-statement).\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\raksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:272\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m p \u001b[39m=\u001b[39m Path(p)\n\u001b[0;32m    271\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mverbose \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39msave \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39msave_txt \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshow:\n\u001b[1;32m--> 272\u001b[0m     s \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_results(i, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresults, (p, im, im0))\n\u001b[0;32m    273\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39msave \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39msave_txt:\n\u001b[0;32m    274\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults[i]\u001b[39m.\u001b[39msave_dir \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_dir\u001b[39m.\u001b[39m\u001b[39m__str__\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\raksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:177\u001b[0m, in \u001b[0;36mBasePredictor.write_results\u001b[1;34m(self, idx, results, batch)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mretina_masks:\n\u001b[0;32m    176\u001b[0m         plot_args[\u001b[39m'\u001b[39m\u001b[39mim_gpu\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m im[idx]\n\u001b[1;32m--> 177\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplotted_img \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39;49mplot(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mplot_args)\n\u001b[0;32m    178\u001b[0m \u001b[39m# Write\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39msave_txt:\n",
      "File \u001b[1;32mc:\\Users\\raksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\results.py:258\u001b[0m, in \u001b[0;36mResults.plot\u001b[1;34m(self, conf, line_width, font_size, font, pil, img, im_gpu, kpt_radius, kpt_line, labels, boxes, masks, probs, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m         name \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid:\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mid\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m names[c]\n\u001b[0;32m    257\u001b[0m         label \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconf\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m conf \u001b[39melse\u001b[39;00m name) \u001b[39mif\u001b[39;00m labels \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 258\u001b[0m         annotator\u001b[39m.\u001b[39;49mbox_label(d\u001b[39m.\u001b[39;49mxyxy\u001b[39m.\u001b[39;49msqueeze(), label, color\u001b[39m=\u001b[39;49mcolors(c, \u001b[39mTrue\u001b[39;49;00m))\n\u001b[0;32m    260\u001b[0m \u001b[39m# Plot Classify results\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[39mif\u001b[39;00m pred_probs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m show_probs:\n",
      "File \u001b[1;32mc:\\Users\\raksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\plotting.py:120\u001b[0m, in \u001b[0;36mAnnotator.box_label\u001b[1;34m(self, box, label, color, txt_color)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# cv2\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     p1, p2 \u001b[39m=\u001b[39m (\u001b[39mint\u001b[39m(box[\u001b[39m0\u001b[39m]), \u001b[39mint\u001b[39m(box[\u001b[39m1\u001b[39m])), (\u001b[39mint\u001b[39m(box[\u001b[39m2\u001b[39m]), \u001b[39mint\u001b[39m(box[\u001b[39m3\u001b[39m]))\n\u001b[1;32m--> 120\u001b[0m     cv2\u001b[39m.\u001b[39;49mrectangle(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mim, p1, p2, color, thickness\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlw, lineType\u001b[39m=\u001b[39;49mcv2\u001b[39m.\u001b[39;49mLINE_AA)\n\u001b[0;32m    121\u001b[0m     \u001b[39mif\u001b[39;00m label:\n\u001b[0;32m    122\u001b[0m         tf \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlw \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)  \u001b[39m# font thickness\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result=model.predict(source='0', save=True, imgsz=320, conf=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'cv2.VideoCapture' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pickle\u001b[39m.\u001b[39;49mdump(cap,\u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mclf.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle 'cv2.VideoCapture' object"
     ]
    }
   ],
   "source": [
    "pickle.dump(cap,open('clf.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_model=pickle.load(open('clf.pkl','rb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
